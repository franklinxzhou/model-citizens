{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "from f2_preprocessor import Preprocessor\n",
    "\n",
    "import optuna\n",
    "\n",
    "from tabm import TabM\n",
    "from rtdl_num_embeddings import LinearReLUEmbeddings  # simple but good :contentReference[oaicite:1]{index=1}\n",
    "from focal_loss import FocalBCEWithLogitsLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"year_of_born\",\n",
    "    \"email_or_tel_available\",\n",
    "    \"safety_rating\",\n",
    "    \"annual_income\",\n",
    "    \"high_education_ind\",\n",
    "    \"address_change_ind\",\n",
    "    \"past_num_of_claims\",\n",
    "    \"liab_prct\",\n",
    "    \"policy_report_filed_ind\",\n",
    "    \"claim_est_payout\",\n",
    "    \"vehicle_made_year\",\n",
    "    \"vehicle_price\",\n",
    "    \"vehicle_weight\",\n",
    "    \"age_of_DL\",\n",
    "    \"vehicle_mileage\",\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    \"gender\",\n",
    "    \"living_status\",\n",
    "    \"zip_code\",\n",
    "    \"claim_day_of_week\",\n",
    "    \"accident_site\",\n",
    "    \"witness_present_ind\",\n",
    "    \"channel\",\n",
    "    \"vehicle_category\",\n",
    "    \"vehicle_color\",\n",
    "    \"accident_type\",\n",
    "    \"in_network_bodyshop\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_f1(probs: np.ndarray,\n",
    "                    targets: np.ndarray,\n",
    "                    thresholds: np.ndarray | None = None):\n",
    "    \"\"\"\n",
    "    probs:    shape (N,), predicted positive probabilities\n",
    "    targets:  shape (N,), 0/1 labels\n",
    "    thresholds: optional array of candidate thresholds (0..1)\n",
    "\n",
    "    Returns (best_f1, best_threshold)\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        # Coarse but reasonable grid; you can make it denser if you want\n",
    "        thresholds = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_t = 0.5\n",
    "\n",
    "    for t in thresholds:\n",
    "        preds = (probs >= t).astype(int)\n",
    "        f1 = f1_score(targets, preds, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "\n",
    "    return best_f1, best_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Training_TriGuard.csv\")\n",
    "df = df.dropna(subset=['subrogation'])\n",
    "\n",
    "df = df.drop(columns=[\"claim_number\"], errors=\"ignore\")\n",
    "\n",
    "target_col = \"subrogation\"\n",
    "y_all = df[target_col].to_numpy().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_num_features: int,\n",
    "                cat_cardinalities,\n",
    "                trial: optuna.Trial) -> nn.Module:\n",
    "    # EDIT: tighten but beef up architecture search space\n",
    "    n_blocks = trial.suggest_int(\"n_blocks\", 3, 5)                 # was 2–5\n",
    "    d_block  = trial.suggest_int(\"d_block\", 384, 1024, log=True)   # was 256–1024\n",
    "    dropout  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    k        = trial.suggest_int(\"k\", 8, 32, step=8)               # keep 8–32\n",
    "\n",
    "    num_emb = LinearReLUEmbeddings(n_num_features)\n",
    "\n",
    "    model = TabM.make(\n",
    "        n_num_features=n_num_features,\n",
    "        num_embeddings=num_emb,\n",
    "        cat_cardinalities=cat_cardinalities,\n",
    "        d_out=1,\n",
    "        n_blocks=n_blocks,\n",
    "        d_block=d_block,\n",
    "        dropout=dropout,\n",
    "        k=k,\n",
    "    )\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_oof_tabm(df, target_col, num_cols, cat_cols,\n",
    "                 best_params, n_splits=5, device=device):\n",
    "    \"\"\"\n",
    "    Run K-fold OOF CV with fixed best_params to get:\n",
    "      - oof_probs: out-of-fold probabilities for each training row\n",
    "      - oof_targets: true labels\n",
    "      - global_best_f1, global_best_t: OOF-based threshold and F1\n",
    "    \"\"\"\n",
    "\n",
    "    y_all = df[target_col].astype(int).to_numpy()\n",
    "    oof_probs = np.zeros_like(y_all, dtype=float)\n",
    "\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    fixed_trial = optuna.trial.FixedTrial(best_params)\n",
    "\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(df, y_all)):\n",
    "        print(f\"\\n=== OOF Fold {fold_idx+1}/{n_splits} ===\")\n",
    "\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        valid_df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "        # --- Preprocess for this fold ---\n",
    "        preproc = Preprocessor(\n",
    "            num_cols=num_cols,\n",
    "            cat_cols=cat_cols,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "\n",
    "        X_num_train, X_cat_train, y_train = preproc.fit_transform(train_df)\n",
    "        X_num_valid, X_cat_valid, y_valid = preproc.transform(valid_df)\n",
    "\n",
    "        # --- Build model with best architecture ---\n",
    "        n_num_features = X_num_train.shape[1]\n",
    "        cat_cardinalities = [preproc.cat_cardinalities_[c] for c in cat_cols]\n",
    "\n",
    "        model = build_model(\n",
    "            n_num_features=n_num_features,\n",
    "            cat_cardinalities=cat_cardinalities,\n",
    "            trial=fixed_trial,\n",
    "        ).to(device)\n",
    "\n",
    "        # --- Hyperparams from best_params ---\n",
    "        lr = best_params[\"lr\"]\n",
    "        weight_decay = best_params[\"weight_decay\"]\n",
    "        batch_size = best_params[\"batch_size\"]\n",
    "        n_epochs = best_params[\"n_epochs\"]\n",
    "\n",
    "        # --- Tensors & datasets ---\n",
    "        X_num_tr_t = torch.from_numpy(X_num_train)\n",
    "        X_cat_tr_t = torch.from_numpy(X_cat_train)\n",
    "        y_tr_t = torch.from_numpy(y_train)\n",
    "\n",
    "        X_num_va_t = torch.from_numpy(X_num_valid)\n",
    "        X_cat_va_t = torch.from_numpy(X_cat_valid)\n",
    "        y_va_t = torch.from_numpy(y_valid)\n",
    "\n",
    "        train_dataset = TensorDataset(X_num_tr_t, X_cat_tr_t, y_tr_t)\n",
    "        valid_dataset = TensorDataset(X_num_va_t, X_cat_va_t, y_va_t)\n",
    "\n",
    "        # --- Imbalance-aware sampler (same idea as before) ---\n",
    "        y_train_flat = y_train.ravel()\n",
    "        class_counts = np.bincount(y_train_flat.astype(int))\n",
    "        class_counts = np.maximum(class_counts, 1)\n",
    "        class_weights = 1.0 / class_counts\n",
    "        sample_weights = class_weights[y_train_flat.astype(int)]\n",
    "\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=torch.from_numpy(sample_weights).float(),\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True,\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        # --- Loss & optimizer ---\n",
    "        # Use the *same* choice you used for final training (BCE or focal).\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "\n",
    "        # --- Train ---\n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for Xn_b, Xc_b, yb in train_loader:\n",
    "                Xn_b = Xn_b.to(device)\n",
    "                Xc_b = Xc_b.to(device)\n",
    "                yb = yb.to(device)\n",
    "\n",
    "                logits = model(Xn_b, Xc_b)       # (B, k, 1)\n",
    "                B, k, _ = logits.shape\n",
    "                logits_flat = logits.reshape(B * k, 1)\n",
    "                y_flat = yb.repeat_interleave(k, dim=0)\n",
    "\n",
    "                loss = criterion(logits_flat, y_flat)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            if (epoch + 1) % max(1, n_epochs // 3) == 0:\n",
    "                print(f\"  epoch {epoch+1}/{n_epochs}, loss={running_loss:.4f}\")\n",
    "\n",
    "        # --- Collect OOF probs for this fold ---\n",
    "        model.eval()\n",
    "        fold_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xn_b, Xc_b, yb in valid_loader:\n",
    "                Xn_b = Xn_b.to(device)\n",
    "                Xc_b = Xc_b.to(device)\n",
    "\n",
    "                logits = model(Xn_b, Xc_b)                   # (B, k, 1)\n",
    "                probs = torch.sigmoid(logits).mean(dim=1)    # (B, 1)\n",
    "                probs = probs.squeeze(-1).cpu().numpy()\n",
    "                fold_probs.append(probs)\n",
    "\n",
    "        fold_probs = np.concatenate(fold_probs)\n",
    "        assert len(valid_idx) == len(fold_probs)\n",
    "        oof_probs[valid_idx] = fold_probs\n",
    "\n",
    "    # --- Global OOF threshold ---\n",
    "    global_best_f1, global_best_t = compute_best_f1(oof_probs, y_all)\n",
    "    print(\"\\n=== Global OOF Results ===\")\n",
    "    print(f\"Global OOF F1: {global_best_f1:.6f} at threshold {global_best_t:.4f}\")\n",
    "\n",
    "    return oof_probs, y_all, global_best_f1, global_best_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(model,\n",
    "                   train_loader,\n",
    "                   valid_loader,\n",
    "                   n_epochs: int,\n",
    "                   lr: float,\n",
    "                   weight_decay: float,\n",
    "                   # pos_weight_eff: float\n",
    "                   ) -> float:\n",
    "    # EDIT: pass in effective pos_weight (after scaling)\n",
    "    # pos_weight = torch.tensor([pos_weight_eff], device=device)\n",
    "    criterion = FocalBCEWithLogitsLoss(alpha=0.75, gamma=2.0)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    # -------- TRAIN --------\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for X_num_b, X_cat_b, y_b in train_loader:\n",
    "            X_num_b = X_num_b.to(device)\n",
    "            X_cat_b = X_cat_b.to(device)\n",
    "            y_b = y_b.to(device)   # (B, 1)\n",
    "\n",
    "            logits = model(X_num_b, X_cat_b)          # (B, k, 1)\n",
    "            B, k, _ = logits.shape\n",
    "\n",
    "            # EDIT: use reshape instead of view\n",
    "            logits_flat = logits.reshape(B * k, 1)    # (B*k, 1)\n",
    "            y_flat = y_b.repeat_interleave(k, dim=0)  # (B*k, 1)\n",
    "\n",
    "            loss = criterion(logits_flat, y_flat)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # -------- VALID: compute probs and F1 --------\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_num_b, X_cat_b, y_b in valid_loader:\n",
    "            X_num_b = X_num_b.to(device)\n",
    "            X_cat_b = X_cat_b.to(device)\n",
    "            y_b = y_b.to(device)\n",
    "\n",
    "            logits = model(X_num_b, X_cat_b)              # (B, k, 1)\n",
    "            probs = torch.sigmoid(logits).mean(dim=1)     # (B, 1)\n",
    "            probs = probs.squeeze(-1).cpu().numpy()\n",
    "            targets = y_b.squeeze(-1).cpu().numpy()\n",
    "\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    # Optional defensive mask\n",
    "    mask = ~np.isnan(all_probs) & ~np.isnan(all_targets)\n",
    "    all_probs = all_probs[mask]\n",
    "    all_targets = all_targets[mask]\n",
    "\n",
    "    if len(np.unique(all_targets)) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    best_f1, best_t = compute_best_f1(all_probs, all_targets)\n",
    "    return float(best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Hyperparameters for TabM\n",
    "    lr = trial.suggest_float(\"lr\", 5e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 20, 40)\n",
    "\n",
    "    # NO pos_weight here anymore\n",
    "\n",
    "    n_splits = 3\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    fold_f1s = []\n",
    "\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(df, y_all)):\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        valid_df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "        preproc = Preprocessor(\n",
    "            num_cols=num_cols,\n",
    "            cat_cols=cat_cols,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "\n",
    "        X_num_train, X_cat_train, y_train = preproc.fit_transform(train_df)\n",
    "        X_num_valid, X_cat_valid, y_valid = preproc.transform(valid_df)\n",
    "\n",
    "        n_num_features = X_num_train.shape[1]\n",
    "        cat_cardinalities = [\n",
    "            preproc.cat_cardinalities_[c] for c in cat_cols\n",
    "        ]\n",
    "\n",
    "        model = build_model(n_num_features, cat_cardinalities, trial)\n",
    "\n",
    "        X_num_tr_t = torch.from_numpy(X_num_train)\n",
    "        X_cat_tr_t = torch.from_numpy(X_cat_train)\n",
    "        y_tr_t = torch.from_numpy(y_train)\n",
    "\n",
    "        X_num_va_t = torch.from_numpy(X_num_valid)\n",
    "        X_cat_va_t = torch.from_numpy(X_cat_valid)\n",
    "        y_va_t = torch.from_numpy(y_valid)\n",
    "\n",
    "        train_dataset = TensorDataset(X_num_tr_t, X_cat_tr_t, y_tr_t)\n",
    "        valid_dataset = TensorDataset(X_num_va_t, X_cat_va_t, y_va_t)\n",
    "\n",
    "        # Imbalance-aware sampler (this alone is OK)\n",
    "        y_train_flat = y_train.ravel()\n",
    "        class_counts = np.bincount(y_train_flat.astype(int))\n",
    "        class_counts = np.maximum(class_counts, 1)\n",
    "        class_weights = 1.0 / class_counts\n",
    "        sample_weights = class_weights[y_train_flat.astype(int)]\n",
    "\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=torch.from_numpy(sample_weights).float(),\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True,\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        fold_f1 = train_one_fold(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            n_epochs=n_epochs,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            # no pos_weight_eff here\n",
    "        )\n",
    "        fold_f1s.append(fold_f1)\n",
    "\n",
    "        trial.report(fold_f1, step=fold_idx)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    mean_f1 = float(np.mean(fold_f1s))\n",
    "    return mean_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:06:18,515] A new study created in memory with name: tabm_subrogation_cv_f1\n",
      "Best trial: 0. Best value: 0.372162:   2%|▏         | 1/50 [10:42<8:45:03, 642.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:17:01,440] Trial 0 finished with value: 0.37216242076746936 and parameters: {'lr': 0.009594805377504345, 'weight_decay': 0.001471509843215915, 'batch_size': 64, 'n_epochs': 34, 'n_blocks': 5, 'd_block': 426, 'dropout': 0.1248820182171233, 'k': 32}. Best is trial 0 with value: 0.37216242076746936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.372162:   4%|▍         | 2/50 [15:22<5:43:08, 428.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:21:40,581] Trial 1 finished with value: 0.37216242076746936 and parameters: {'lr': 0.0005853753666740638, 'weight_decay': 0.00011930776451925345, 'batch_size': 64, 'n_epochs': 24, 'n_blocks': 3, 'd_block': 715, 'dropout': 0.22457869381193063, 'k': 16}. Best is trial 0 with value: 0.37216242076746936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.372162:   6%|▌         | 3/50 [18:45<4:15:29, 326.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:25:04,449] Trial 2 finished with value: 0.37216242076746936 and parameters: {'lr': 0.0021426029456718676, 'weight_decay': 1.0630538987061776e-05, 'batch_size': 128, 'n_epochs': 31, 'n_blocks': 5, 'd_block': 540, 'dropout': 0.3727842333347411, 'k': 8}. Best is trial 0 with value: 0.37216242076746936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.372162:   8%|▊         | 4/50 [20:37<3:05:01, 241.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:26:55,750] Trial 3 finished with value: 0.37216242076746936 and parameters: {'lr': 0.005344129122935598, 'weight_decay': 0.0058424215890045235, 'batch_size': 128, 'n_epochs': 22, 'n_blocks': 4, 'd_block': 472, 'dropout': 0.352038791456758, 'k': 8}. Best is trial 0 with value: 0.37216242076746936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.372162:   8%|▊         | 4/50 [25:17<4:50:50, 379.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-13 20:31:35,982] Trial 4 failed with parameters: {'lr': 0.0024117749699391626, 'weight_decay': 0.00019740776764004176, 'batch_size': 256, 'n_epochs': 38, 'n_blocks': 4, 'd_block': 888, 'dropout': 0.13374842445226798, 'k': 16} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/cb/0wwk4_d90ps1fw1_wg2m60340000gn/T/ipykernel_17526/4284683966.py\", line 76, in objective\n",
      "    fold_f1 = train_one_fold(\n",
      "        model=model,\n",
      "    ...<5 lines>...\n",
      "        # no pos_weight_eff here\n",
      "    )\n",
      "  File \"/var/folders/cb/0wwk4_d90ps1fw1_wg2m60340000gn/T/ipykernel_17526/507404640.py\", line 27, in train_one_fold\n",
      "    logits = model(X_num_b, X_cat_b)          # (B, k, 1)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tabm.py\", line 1803, in forward\n",
      "    x = self.backbone(x)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tabm.py\", line 1422, in forward\n",
      "    x = block(x)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/dropout.py\", line 73, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py\", line 1418, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-13 20:31:35,990] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m pruner = optuna.pruners.MedianPruner(n_warmup_steps=\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m study = optuna.create_study(\n\u001b[32m      4\u001b[39m     direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     study_name=\u001b[33m\"\u001b[39m\u001b[33mtabm_subrogation_cv_f1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     pruner=pruner\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest mean CV F1:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     63\u001b[39m train_loader = DataLoader(\n\u001b[32m     64\u001b[39m     train_dataset,\n\u001b[32m     65\u001b[39m     batch_size=batch_size,\n\u001b[32m     66\u001b[39m     sampler=sampler,\n\u001b[32m     67\u001b[39m     drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     68\u001b[39m )\n\u001b[32m     69\u001b[39m valid_loader = DataLoader(\n\u001b[32m     70\u001b[39m     valid_dataset,\n\u001b[32m     71\u001b[39m     batch_size=batch_size,\n\u001b[32m     72\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     73\u001b[39m     drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     74\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m fold_f1 = \u001b[43mtrain_one_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# no pos_weight_eff here\u001b[39;49;00m\n\u001b[32m     84\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m fold_f1s.append(fold_f1)\n\u001b[32m     87\u001b[39m trial.report(fold_f1, step=fold_idx)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_one_fold\u001b[39m\u001b[34m(model, train_loader, valid_loader, n_epochs, lr, weight_decay)\u001b[39m\n\u001b[32m     24\u001b[39m X_cat_b = X_cat_b.to(device)\n\u001b[32m     25\u001b[39m y_b = y_b.to(device)   \u001b[38;5;66;03m# (B, 1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_num_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_cat_b\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# (B, k, 1)\u001b[39;00m\n\u001b[32m     28\u001b[39m B, k, _ = logits.shape\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# EDIT: use reshape instead of view\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tabm.py:1803\u001b[39m, in \u001b[36mTabM.forward\u001b[39m\u001b[34m(self, x_num, x_cat)\u001b[39m\n\u001b[32m   1800\u001b[39m     x = x.unflatten(\u001b[32m0\u001b[39m, (batch_size, \u001b[38;5;28mself\u001b[39m.backbone.k))  \u001b[38;5;66;03m# (B * K, D) -> (B, K, D)\u001b[39;00m\n\u001b[32m   1802\u001b[39m x = \u001b[38;5;28mself\u001b[39m.ensemble_view(x)\n\u001b[32m-> \u001b[39m\u001b[32m1803\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1805\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.output(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tabm.py:1422\u001b[39m, in \u001b[36mMLPBackboneBatchEnsemble.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1420\u001b[39m _check_input_min_ndim(x, \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m)\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=1)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"tabm_subrogation_cv_f1\",\n",
    "    pruner=pruner\n",
    ")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"Best mean CV F1:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.0011183425690718294, 'weight_decay': 0.004187499814600279, 'batch_size': 64, 'n_epochs': 33, 'pos_weight_scale': 2.159985493642329, 'n_blocks': 4, 'd_block': 455, 'dropout': 0.18355459979095332, 'k': 24}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NEW: get OOF-based threshold using best_params ---\n",
    "oof_probs, oof_targets, oof_f1, oof_t = run_oof_tabm(\n",
    "    df=df,\n",
    "    target_col=target_col,\n",
    "    num_cols=num_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    best_params=best_params,\n",
    "    n_splits=5,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"OOF F1:\", oof_f1)\n",
    "print(\"OOF best threshold:\", oof_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit preprocessor on the full training data\n",
    "preproc_final = Preprocessor(num_cols=num_cols, cat_cols=cat_cols, target_col=target_col)\n",
    "X_num_full, X_cat_full, y_full = preproc_final.fit_transform(df)\n",
    "\n",
    "# Prepare tensors\n",
    "X_num_full_t = torch.from_numpy(X_num_full)\n",
    "X_cat_full_t = torch.from_numpy(X_cat_full)\n",
    "y_full_t     = torch.from_numpy(y_full)\n",
    "\n",
    "full_dataset = TensorDataset(X_num_full_t, X_cat_full_t, y_full_t)\n",
    "\n",
    "full_loader = DataLoader(\n",
    "    full_dataset,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final TabM model from best params\n",
    "model_final = build_model(\n",
    "    n_num_features=X_num_full.shape[1],\n",
    "    cat_cardinalities=[preproc_final.cat_cardinalities_[c] for c in cat_cols],\n",
    "    trial=optuna.trial.FixedTrial(best_params)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/33, loss=140.5011\n",
      "Epoch 10/33, loss=121.5093\n",
      "Epoch 15/33, loss=113.7620\n",
      "Epoch 20/33, loss=112.7051\n",
      "Epoch 25/33, loss=111.7766\n",
      "Epoch 30/33, loss=111.8216\n"
     ]
    }
   ],
   "source": [
    "criterion = FocalBCEWithLogitsLoss(alpha=0.75, gamma=2.0)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_final.parameters(),\n",
    "    lr=best_params[\"lr\"],\n",
    "    weight_decay=best_params[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "n_epochs = best_params[\"n_epochs\"]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model_final.train()\n",
    "    running_loss = 0.0\n",
    "    for Xn, Xc, yb in full_loader:\n",
    "        Xn = Xn.to(device)\n",
    "        Xc = Xc.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        logits = model_final(Xn, Xc)        # (B, k, 1)\n",
    "        B, k, _ = logits.shape\n",
    "        logits_flat = logits.reshape(B * k, 1)\n",
    "        y_flat = yb.repeat_interleave(k, dim=0)\n",
    "\n",
    "        loss = criterion(logits_flat, y_flat)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, loss={running_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train probs min/mean/max: 0.0005119745 0.25603554 0.842113\n",
      "Train F1 @0.3: 0.5988591317799478\n",
      "Train confusion @0.5:\n",
      " [[12912   972]\n",
      " [ 2268  1847]]\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic Code\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "model_final.eval()\n",
    "with torch.no_grad():\n",
    "    Xn_tr = X_num_full_t.to(device)\n",
    "    Xc_tr = X_cat_full_t.to(device)\n",
    "    logits_tr = model_final(Xn_tr, Xc_tr)                 # (N, k, 1)\n",
    "    probs_tr = torch.sigmoid(logits_tr).mean(dim=1)       # (N, 1)\n",
    "    probs_tr = probs_tr.squeeze(-1).cpu().numpy()\n",
    "\n",
    "print(\"Train probs min/mean/max:\", probs_tr.min(), probs_tr.mean(), probs_tr.max())\n",
    "\n",
    "y_train_true = y_full.ravel().astype(int)\n",
    "y_train_pred_03 = (probs_tr >= 0.3).astype(int)\n",
    "\n",
    "print(\"Train F1 @0.3:\", f1_score(y_train_true, y_train_pred_03))\n",
    "print(\"Train confusion @0.5:\\n\", confusion_matrix(y_train_true, y_train_pred_05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 on train: 0.5988591317799478\n",
      "Best threshold: 0.3\n"
     ]
    }
   ],
   "source": [
    "best_f1_train, best_t_train = compute_best_f1(probs_tr, y_full.ravel().astype(int))\n",
    "print(\"Best F1 on train:\", best_f1_train)\n",
    "print(\"Best threshold:\", best_t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = pd.read_csv(\"data/Testing_TriGuard.csv\")\n",
    "\n",
    "# Keep columns needed for domain features\n",
    "claim_numbers = real_test[\"claim_number\"].copy()\n",
    "\n",
    "# Use the final preprocessor (fit on full training data!)\n",
    "X_num_test, X_cat_test, _ = preproc_final.transform(real_test)\n",
    "\n",
    "X_num_test_t = torch.from_numpy(X_num_test)\n",
    "X_cat_test_t = torch.from_numpy(X_cat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.eval()\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    Xn = X_num_test_t.to(device)\n",
    "    Xc = X_cat_test_t.to(device)\n",
    "\n",
    "    logits = model_final(Xn, Xc)                 # (N, k, 1)\n",
    "    probs = torch.sigmoid(logits).mean(dim=1)    # (N, 1)\n",
    "    probs = probs.squeeze(-1).cpu().numpy()\n",
    "\n",
    "    all_probs = probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred_proba = all_probs\n",
    "real_pred_label = (real_pred_proba >= oof_t).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob: 0.0007758692\n",
      "Max prob: 0.82720715\n",
      "Mean prob: 0.25367633\n",
      "First 20 probs: [0.21576667 0.3347236  0.06319809 0.609448   0.36384344 0.03800942\n",
      " 0.45161465 0.06597612 0.23697914 0.66205806 0.09418901 0.47217855\n",
      " 0.2660694  0.2500148  0.22387505 0.58648896 0.054098   0.04736322\n",
      " 0.15361674 0.4636856 ]\n",
      "First 20 labels: [0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1]\n",
      "Unique labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic Code\n",
    "\n",
    "print(\"Min prob:\", real_pred_proba.min())\n",
    "print(\"Max prob:\", real_pred_proba.max())\n",
    "print(\"Mean prob:\", real_pred_proba.mean())\n",
    "print(\"First 20 probs:\", real_pred_proba[:20])\n",
    "print(\"First 20 labels:\", real_pred_label[:20])\n",
    "print(\"Unique labels:\", np.unique(real_pred_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/tabm_5938_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame({\n",
    "    \"claim_number\": claim_numbers,\n",
    "    \"subrogation\": real_pred_label\n",
    "})\n",
    "\n",
    "prediction.to_csv(\"results/tabm_xxxx_prediction.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", \"results/tabm_xxxx_prediction.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Saving Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TabM_save_load import TabM_save_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabM pipeline saved successfully to models/tabm_full_pipeline_5938\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the pipeline wrapper\n",
    "pipeline = TabM_save_load(\n",
    "    model=model_final,\n",
    "    preprocessor=preproc_final,\n",
    "    threshold=oof_t, \n",
    "    best_params=best_params,\n",
    "    num_cols=num_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# 2. Save everything to a folder\n",
    "save_dir = \"models/tabm_full_pipeline_xxxx\"\n",
    "pipeline.save(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

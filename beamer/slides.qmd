---
title: "Predicting Opportunity of Subrogation with Real Claim Data"
subtitle: "Model Citizens, 2025 Travelers UMC"
author: "Wenjie Gong, Cecilia Liu, Simeng Wu, Carol Zhou, Franklin Zhou"
institute: "Department of Statistical Science, Duke University"
format: 
    beamer:
        navigation: horizontal
header-includes:
  - \titlegraphic{\includegraphics[width=0.4\paperwidth]{duke_university_wordmark_navyblue_012169.png}} 
  - \usepackage{tabularx}
  - \usepackage[none]{hyphenat}
  - \setbeamertemplate{itemize items}[ball]
  - \usepackage{tikz}
  - \usetikzlibrary{shapes.geometric, arrows.meta, positioning}
  - |
      \definecolor{dukeblue}{HTML}{012169}
      \addtobeamertemplate{background}{%
        \begin{tikzpicture}[remember picture,overlay]
          \draw[dukeblue, line width=7pt]
            (current page.north west) rectangle (current page.south east);
        \end{tikzpicture}
      }{}
---

## Introduction

**Business Context**  
Subrogation is a critical part of the claim lifecycle. When a third party is liable, recovery reduces net incurred loss, improves loss ratios, and enhances reserving accuracy—making subrogation a key financial and loss-mitigation lever.

**The Core Challenge**  
Current subrogation identification relies heavily on adjuster judgment and manual file review. This process is slow, inconsistent, and often results in missed recovery opportunities across thousands of claims.


## Subrogation Modeling Framework

**Our Mission**  
Build a predictive model using 2020–2021 first-party physical damage claims to flag potential subrogation opportunities, identify key indicators, and provide recommendations for operational use.

**Modeling Objective**  
Predict a binary outcome *Subrogation Opportunity*  
(1 = likely recovery, 0 = not likely).  
Evaluation Metric: \textcolor{red}{F1 score} (balances precision and recall due to asymmetric business costs).

**Business Value**

- Improve recovery rates and reduce net incurred losses  
- Help subrogation specialists prioritize high-value cases  
- Reduce time spent on low-likelihood opportunities  
- Support data-driven decision-making in the claims process  


## Data Overview
\scriptsize

::: columns
::: column

![](target_var.png){width=90%}

![](num_box.png){width=90%}

:::

::: column

**Dataset Summary**  
- Training set: **18,000** rows with binary subrogation indicator  
- Test set: **12,000** rows without the indicator  
- Features describe policyholder, driver, vehicle, accident context, and estimated payout  

**Data Quality Steps**  
- Removed **2** training rows with missing subrogation indicator  
- Test set contains **no missing values**  
- Dropped `vehicle_made_year` (inconsistent with claim date) and `age_of_vehicle` (unreliable)  

**General Patterns**  
- Several numeric features exhibit skewness  
- Subrogation indicator is **imbalanced** (few positives)  
- `liab_prct` is strongly associated with the target  

:::
:::

## We Leverages Multiple Model Families

- **Linear Model**: Logistic Regression with LASSO  
- **Tree-based Models**: XGBoost, CatBoost, LightGBM, LogitBoost, Random Forest  
- **MLP-based Models**: TabM

## Why We Used Multiple Preprocessing Pipelines?
\footnotesize

Each model family has its own optimized pipeline, in accordance with their algorithm characteristics.

\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.25}
\begin{tabularx}{\textwidth}{l|X|X|X|X|X}
\hline
\textbf{Model} 
& \textbf{TabM} 
& \textbf{Linear Model} 
& \textbf{CatBoost} 
& \textbf{LightGBM} 
& \textbf{XGBoost} \\
\hline
\textbf{Numerical} 
& Normalize (quantile or z-score)
& Normalize (z-score)
& Works well with raw data
& Works well with raw data
& Works well with raw data \\
\hline
\textbf{Categorical} 
& One-Hot Encoding
& One-Hot Encoding
& Native handling
& Native handling
& One-Hot Encoding \\
\hline
\end{tabularx}
\end{table}

## Comparison of Preprocessing Pipelines for GBMs

- LightGBM uses an aggressive, high-complexity pipeline, generating the most features through extensive transformations like 3-way interactions, binning, and Z-scores.
- CatBoost adopts a minimalist strategy, keeping numerical data raw and leaving categoricals in the string form to leverage its native handling, with very little manual feature engineering.
- XGBoost strikes something in between, applying moderate scaling and feature creation while converting categorical values into integers.


## Sample Workflow
\begin{center}
\begin{tikzpicture}[
    scale=0.78,
    transform shape,
    node distance=0.42cm,
    >=latex,
    box/.style={
        rectangle,
        rounded corners=3pt,
        draw=blue!60,
        fill=blue!10,
        very thick,
        minimum width=6cm,
        minimum height=0.8cm,
        align=center,
    }
]

\node (A) [box] {Raw Datasets};
\node (B) [box, below=of A] {Data Cleaning};
\node (C) [box, below=of B] {Feature Engineering};
\node (D) [box, below=of C] {Model Selection};
\node (E) [box, below=of D] {Hyperparameter Tuning};
\node (F) [box, below=of E] {Model Training};
\node (G) [box, below=of F] {Evaluation};
\node (H) [box, below=of G] {Inference Pipeline};
\node (I) [box, below=of H] {Output};

\draw[->, thick] (A) -- (B);
\draw[->, thick] (B) -- (C);
\draw[->, thick] (C) -- (D);
\draw[->, thick] (D) -- (E);
\draw[->, thick] (E) -- (F);
\draw[->, thick] (F) -- (G);
\draw[->, thick] (G) -- (H);
\draw[->, thick] (H) -- (I);

\end{tikzpicture}
\end{center}

## Motivation for Majority Voting: Wisdom of the Crowd

- While we obtained decent individual models, aggregating opinions from multiple models is a good way to optimize bias and variance

\begin{theorem}[Condorcet's Jury Theorem]
If each invidual model outperforms random guessing ($p>0.5$) and is independent, the probability of majority voting being correct approaches 1 as such models are added.
\end{theorem}

- According to Condorcet's Jury Theorem, the majority voting is likely to produce a better prediction than individual models
- The systematic error on specific feature subspaces of each individual model is now overridden by the consensus of others, leading to a smaller model bias
- Overfitting is mitigated as the a single model might obsess over a tiny, unimportant detail in the data, while the group ignores these details and focuses on the main trends


## Why We Choose Majority Voting Ensemble 

Majority Voting is better then stacking, because

- We trained each individual model with a tailor-made preprocessing pipeline, to optimize the individual model performance
- Stacking requires a unified input feature matrix
- If we use one unified preprocessing pipeline to retrain individual models, their performance will greatly degrade

Majority Voting is better than weighted majority, because

- For validation set performance, XGBoost > CatBoost > TabM
- For test set performance (per private score): TabM > CatBoost > XGBoost
- Majority voting algorithm tends to give XGBoost the highest weight
- The resulting ensemble is an "expert" with validation set but a "failure" with test set

## Majority Voting Ensemble
\footnotesize
\vspace{-0.6em}

\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{l r}
\hline
\textbf{Model}  & \textbf{Public F1} \\
\hline
XGBoost   & 0.60600 \\
CatBoost  & 0.60491 \\
XGBoost   & 0.60352 \\
CatBoost  & 0.60319 \\
TabM      & 0.60298 \\
XGBoost   & 0.60213 \\
LightGBM  & 0.59682 \\
\hline
\end{tabular}

\end{center}

## Feature Selection Across Models
\scriptsize

\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.22}
\begin{tabularx}{\textwidth}{
    >{\raggedright\arraybackslash}p{0.17\textwidth} |
    >{\raggedright\arraybackslash}p{0.38\textwidth} |
    >{\raggedright\arraybackslash}p{0.38\textwidth}
}
\hline
\textbf{Model} & \textbf{Primary Selection Mechanism} & \textbf{Key Differentiator} \\
\hline

XGBoost &
Gain-based split selection using first-order and second-order gradient statistics. &
Precise, curvature-aware feature scoring with strong regularization. \\
\hline

LightGBM &
Histogram-based gain estimation with Exclusive Feature Bundling (EFB). &
Highly efficient and scalable on sparse or high-dimensional tabular data. \\
\hline

CatBoost &
Ordered Target Statistics combined with gain-based splitting on leakage-free categorical encodings. &
Best-in-class categorical handling with minimal overfitting. \\
\hline

TabM (MLP) &
Implicit feature weighting learned through nonlinear layers and gradient-based optimization (no explicit splits). &
Soft, continuous reweighting captures smooth nonlinear interactions. \\

\hline
\end{tabularx}
\end{table}


## SHAP & Feature Importance
\scriptsize

\begin{center}
\includegraphics[width=0.53\textwidth]{XGBoost_SHAP.png}
\end{center}

\small
Compared to the feature importance plots of other models, **liab_prct**, **witness_present_ind**, and **in_network_bodyshop** 
consistently surfaced as high-impact predictors.

## Additional Useful Variables

Policyholder behavior

- Telematics / Driving behavior (speeding, hard brakes, miles driven)
- Payment behavior (late payments, lapse tendencies)

Environmental risk

- Weather exposure (hail, hurricanes, freeze events)
- Traffic density or road safety score

Socioeconomic

- Zip-code–level socioeconomic indicators (median income, population density)
- Education level at area level

## Assumption & Robustness Checks 

Tree-based Models

- Checked overfitting via training vs validation scores
- Cross-validation scores stable across folds
- Feature importance consistent across model runs

Deep Tabular Model

- Examined training/validation loss to confirm convergence
- Key variables aligned with tree-based models

Ensemble (Majority Vote)

- Verified diversity via moderate prediction correlations


## Model Evaluation & Results
\scriptsize

\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.25}

\begin{tabularx}{\textwidth}{
    >{\raggedright\arraybackslash}p{0.25\textwidth} |
    >{\raggedright\arraybackslash}p{0.18\textwidth} |
    >{\raggedright\arraybackslash}X
}
\hline
\textbf{Model} & \textbf{Public F1} & \textbf{Note} \\
\hline

Ensemble & 0.60866 & +0.4\% over the best single model; +18\% over benchmark \\
\hline

XGBoost & 0.60600 & Best individual model \\
\hline

CatBoost & 0.60491 & Handled categorical features well \\
\hline

TabM & 0.60298 & Competitive deep-tabular model and consistent across seeds \\
\hline

LightGBM & 0.59682 & Fast training but underperformed compared to XGBoost/CatBoost \\
\hline

Simple XGBoost & 0.51584 & Benchmark \\
\hline

\end{tabularx}
\end{table}

## Limitations
- Many pipelines = complexity
- Harder to interpret combined model
- Majority vote doesn't use calibrated probabilities
- Feature engineering consistency is limited

## Conclusion

We predicted which auto insurance claims are likely to result in successful subrogation using a majority-vote ensemble of XGBoost, CatBoost, LightGBM, and TabM, achieving an 18% improvement over the benchmark and a modest gain over the best single model.

---
center: true
---

# Thank You

# Appendix


## Comparison of Preprocessing Pipelines for GBMs

\footnotesize

We designed three classes of preprocessing pipelines for XGBoost, CatBoost, and LightGBM.

:::: {.columns}

::: {.column width="33%"}

LightGBM

- Has most features (most extensive transformation)
- Creates binary flags for categorical variables
- Applies Z-scores, Log transforms, and bucketing for numerical variables
- Applies aggressive feature engineering, with 2-way/3-way interactions, polynomials, domain-specific flags

:::

::: {.column width="33%"}

CatBoost

- Has least features (minimal transformation)
- Casts categorical values into strings
- Keeps numerical data *as is*
- Approaches feature engineering very conservatively, with only a few ratio features

:::

::: {.column width="33%"}

XGBoost

- Has moderately many features (a balanced approach)
- Casts categorical values into integers
- Applies scaling and some Log transforms for numerical variables
- Applies moderate level of feature engineering with temporal features, interactions, and differences

:::

::::

## Sample Workflow 1 (XGBoost 1)

\begin{center}
\begin{tikzpicture}[
    scale=0.78,
    transform shape,
    node distance=0.40cm,
    >=latex,
    boxL/.style={
        rectangle,
        rounded corners=3pt,
        draw=blue!60,
        fill=blue!10,
        very thick,
        minimum width=4.4cm,
        minimum height=0.8cm,
        align=center,
    },
    boxR/.style={
        rectangle,
        rounded corners=3pt,
        draw=teal!60,
        fill=teal!10,
        very thick,
        minimum width=4.4cm,
        minimum height=0.8cm,
        align=center,
    }
]

% ---------- LEFT COLUMN ----------
\node (A) [boxL] {Raw Input Data\\[-0.2em]{\scriptsize Training / Testing CSVs}};
\node (B) [boxL, below=of A] {Drop Missing Targets\\[-0.2em]{\scriptsize Remove NA subrogation}};
\node (C) [boxL, below=of B] {Train/Test Split\\[-0.2em]{\scriptsize Stratified 70/30}};
\node (D) [boxL, below=of C] {Data Cleaning\\[-0.2em]{\scriptsize Date parse / Fix future years}};
\node (E) [boxL, below=of D] {Feature Engineering\\[-0.2em]{\scriptsize Temporal / Liability / Ratios / Domain}};
\node (F) [boxL, below=of E] {Preprocessing\\[-0.2em]{\scriptsize Income bins / Label Encoding / Align columns}};

% ---------- RIGHT COLUMN ----------
\node (G) [boxR, right=2.8cm of F] {Hyperparameter Tuning\\[-0.2em]{\scriptsize Optuna (F1 objective)}};
\node (H) [boxR,       above=of G] {Model Training\\[-0.2em]{\scriptsize XGBoost (best params)}};
\node (I) [boxR,       above=of H] {Threshold Search\\[-0.2em]{\scriptsize PR curve → Max-F1}};
\node (J) [boxR,       above=of I] {Final Evaluation\\[-0.2em]{\scriptsize F1 / ROC-AUC / PR-AUC}};
\node (K) [boxR,       above=of J] {Inference Pipeline\\[-0.2em]{\scriptsize Preprocess + Predict}};
\node (L) [boxR,       above=of K] {Output\\[-0.2em]{\scriptsize Final Prediction CSV}};

% ---------- ARROWS ----------
\draw[->, thick] (A) -- (B);
\draw[->, thick] (B) -- (C);
\draw[->, thick] (C) -- (D);
\draw[->, thick] (D) -- (E);
\draw[->, thick] (E) -- (F);

\draw[->, thick] (F) -- (G);
\draw[->, thick] (G) -- (H);
\draw[->, thick] (H) -- (I);
\draw[->, thick] (I) -- (J);
\draw[->, thick] (J) -- (K);
\draw[->, thick] (K) -- (L);

\end{tikzpicture}
\end{center}


## Sample Workflow 2 (XGBoost 2)

\begin{center}
\begin{tikzpicture}[
    scale=0.78,
    transform shape,
    node distance=0.40cm,
    >=latex,
    boxL/.style={
        rectangle,
        rounded corners=3pt,
        draw=blue!60,
        fill=blue!10,
        very thick,
        minimum width=4.4cm,
        minimum height=0.8cm,
        align=center,
    },
    boxR/.style={
        rectangle,
        rounded corners=3pt,
        draw=teal!60,
        fill=teal!10,
        very thick,
        minimum width=4.4cm,
        minimum height=0.8cm,
        align=center,
    }
]

% ---------- LEFT COLUMN ----------
\node (A) [boxL] {Data Loading\\[-0.2em]{\scriptsize Read Training/Testing CSVs}};
\node (B) [boxL, below=of A] {Feature Engineering\\[-0.2em]{\scriptsize Dates / Season / Interaction / Logs}};
\node (C) [boxL, below=of B] {Robust Preprocessor\\[-0.2em]{\scriptsize Label Encoding + UNK Handling}};
\node (D) [boxL, below=of C] {Train/Val Split\\[-0.2em]{\scriptsize Stratified Sampling}};
\node (E) [boxL, below=of D] {Feature Selection\\[-0.2em]{\scriptsize XGBoost + SelectFromModel (80 feats)}};
\node (F) [boxL, below=of E] {Hyperparameter Tuning\\[-0.2em]{\scriptsize Optuna (5-fold AP)}};

% ---------- RIGHT COLUMN ----------
\node (G) [boxR, right=2.8cm of F] {Final Model Training\\[-0.2em]{\scriptsize XGBoost w/ Best Params}};
\node (H) [boxR,       above=of G] {Threshold Optimization\\[-0.2em]{\scriptsize PR Curve → Max-F1}};
\node (I) [boxR,       above=of H] {Model Evaluation\\[-0.2em]{\scriptsize F1 / ROC-AUC / PR-AUC / CM}};
\node (J) [boxR,       above=of I] {Model Explainability\\[-0.2em]{\scriptsize SHAP + Perm. Importance}};
\node (K) [boxR,       above=of J] {Inference Pipeline\\[-0.2em]{\scriptsize Preprocess → Predict}};
\node (L) [boxR,       above=of K] {Final Output\\[-0.2em]{\scriptsize prediction.csv}};

% ---------- CONNECTIONS ----------
\draw[->, thick] (A) -- (B);
\draw[->, thick] (B) -- (C);
\draw[->, thick] (C) -- (D);
\draw[->, thick] (D) -- (E);
\draw[->, thick] (E) -- (F);

\draw[->, thick] (F) -- (G);
\draw[->, thick] (G) -- (H);
\draw[->, thick] (H) -- (I);
\draw[->, thick] (I) -- (J);
\draw[->, thick] (J) -- (K);
\draw[->, thick] (K) -- (L);

\end{tikzpicture}
\end{center}


## Sample Workflow 3 (CatBoost)
\begin{center}
\begin{tikzpicture}[
    scale=0.78,
    transform shape,
    node distance=0.40cm,
    >=latex,
    box/.style={
        rectangle,
        rounded corners=3pt,
        draw=blue!60,
        fill=blue!10,
        very thick,
        minimum width=6.0cm,
        minimum height=0.8cm,
        align=center,
    }
]

% ----------- NODES (Single Column) -----------
\node (A) [box] {Raw Input Data\\[-0.2em]{\scriptsize Training/Testing CSVs}};
\node (B) [box, below=of A] {Data Cleaning\\[-0.2em]{\scriptsize Fix missing / inconsistencies}};
\node (C) [box, below=of B] {Feature Engineering\\[-0.2em]{\scriptsize Few ratio features only}};
\node (D) [box, below=of C] {No Preprocessing\\[-0.2em]{\scriptsize Cast categorical values to strings}};
\node (E) [box, below=of D] {Hyperparameter Tuning\\[-0.2em]{\scriptsize Optuna (Cross-validation F1)}};
\node (F) [box, below=of E] {Model Training\\[-0.2em]{\scriptsize CatBoost}};
\node (G) [box, below=of F] {Inference Pipeline\\[-0.2em]{\scriptsize Preprocess → Predict}};
\node (H) [box, below=of G] {Final Output\\[-0.2em]{\scriptsize Prediction CSV}};

% ------------ ARROWS ------------
\draw[->, thick] (A) -- (B);
\draw[->, thick] (B) -- (C);
\draw[->, thick] (C) -- (D);
\draw[->, thick] (D) -- (E);
\draw[->, thick] (E) -- (F);
\draw[->, thick] (F) -- (G);
\draw[->, thick] (G) -- (H);

\end{tikzpicture}
\end{center}

## Sample Workflow 4 (TabM)

\begin{center}
\begin{tikzpicture}[
    scale=0.78,
    transform shape,
    node distance=0.32cm,
    >=latex,
    box/.style={
        rectangle,
        rounded corners=3pt,
        draw=blue!60,
        fill=blue!10,
        very thick,
        minimum width=5.4cm,
        minimum height=0.72cm,
        align=center,
        font=\footnotesize
    }
]

% ----------- NODES -----------
\node (A) [box] {Raw Input Data\\[-0.25em]{\scriptsize Training/Testing CSVs}};
\node (B) [box, below=of A] {Data Cleaning\\[-0.25em]{\scriptsize Fix missing / inconsistencies}};
\node (C) [box, below=of B] {Feature Engineering\\[-0.25em]{\scriptsize Few domain-specific features}};
\node (D) [box, below=of C] {No Preprocessing\\[-0.25em]{\scriptsize Integer indexing (cat.) / NaN checks (num.)}};
\node (E) [box, below=of D] {Hyperparameter Tuning\\[-0.25em]{\scriptsize Optuna (Cross-validation F1)}};
\node (F) [box, below=of E] {Model Training\\[-0.25em]{\scriptsize TabM}};
\node (G) [box, below=of F] {Threshold Selection\\[-0.25em]{\scriptsize Post-hoc threshold optimization}};
\node (H) [box, below=of G] {Inference Pipeline\\[-0.25em]{\scriptsize Preprocess → Predict}};
\node (I) [box, below=of H] {Final Output\\[-0.25em]{\scriptsize Prediction CSV}};

% ----------- ARROWS -----------
\draw[->, thick] (A) -- (B);
\draw[->, thick] (B) -- (C);
\draw[->, thick] (C) -- (D);
\draw[->, thick] (D) -- (E);
\draw[->, thick] (E) -- (F);
\draw[->, thick] (F) -- (G);
\draw[->, thick] (G) -- (H);
\draw[->, thick] (H) -- (I);

\end{tikzpicture}
\end{center}

## Sample Workflow 5 (LightGBM)
\begin{center}
\begin{tikzpicture}[
    scale=0.78,
    transform shape,
    node distance=0.32cm,
    >=latex,
    box/.style={
        rectangle,
        rounded corners=3pt,
        draw=blue!60,
        fill=blue!10,
        very thick,
        minimum width=5.4cm,
        minimum height=0.72cm,
        align=center,
        font=\footnotesize
    }
]

% ----------- NODES -----------
\node (A) [box] {Raw Input Data\\[-0.25em]{\scriptsize Training/Testing CSVs}};
\node (B) [box, below=of A] {Data Cleaning\\[-0.25em]{\scriptsize Drop missing targets, Parse Dates}};
\node (C) [box, below=of B] {Feature Engineering\\[-0.25em]{\scriptsize Temporal, Interactions, Domain Logic Scores}};
\node (D) [box, below=of C] {Preprocessing\\[-0.25em]{\scriptsize Target Encoding, Median Imputation}};
\node (E) [box, below=of D] {Hyperparameter Tuning\\[-0.25em]{\scriptsize Optuna (LightGBM) + Threshold Search}};
\node (F) [box, below=of E] {Cross-Validation\\[-0.25em]{\scriptsize 5-Fold Stratified, PR-Curve Optimization}};
\node (G) [box, below=of F] {Final Training\\[-0.25em]{\scriptsize Retrain on 100\% Data with Best Params}};
\node (H) [box, below=of G] {Inference Pipeline\\[-0.25em]{\scriptsize Apply Global Threshold $\to$ Predict}};
\node (I) [box, below=of H] {Final Output\\[-0.25em]{\scriptsize Submission CSV}};

% ----------- ARROWS -----------
\draw[->, thick] (A) -- (B);
\draw[->, thick] (B) -- (C);
\draw[->, thick] (C) -- (D);
\draw[->, thick] (D) -- (E);
\draw[->, thick] (E) -- (F);
\draw[->, thick] (F) -- (G);
\draw[->, thick] (G) -- (H);
\draw[->, thick] (H) -- (I);

\end{tikzpicture}
\end{center}

## Feature Importance Plots For Different Models
![](XGBoost_importance.png){width=48%}
![](xgboost_im.png){width=48%}
![](CatBoost_im.png){width=48%}
![](TabM_im.png){width=48%}


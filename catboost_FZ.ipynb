{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, roc_auc_score, average_precision_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "\n",
    "from preprocessor import Preprocessor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Training_TriGuard.csv')\n",
    "df = df.dropna(subset=['subrogation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"subrogation\"]).copy()\n",
    "y = df[\"subrogation\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subrogation\n",
       "0.0    0.77141\n",
       "1.0    0.22859\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subrogation\n",
       "0.0    0.771296\n",
       "1.0    0.228704\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proc = pre.fit_transform(X_train)\n",
    "X_test_proc = pre.transform(X_test)\n",
    "\n",
    "X_test_proc = X_test_proc.reindex(columns=X_train_proc.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CatBoost Model (Default Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_clf = cb.CatBoostClassifier(\n",
    "    objective='Logloss',\n",
    "    random_state=42,\n",
    "    thread_count=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x116692660>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf.fit(X_train_proc, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8133333333333334\n",
      "F1 Score: 0.5135135135135135\n",
      "ROC AUC Score: 0.8343265403327322\n",
      "PR AUC (Average Precision): 0.5999310575144581\n",
      "Precision: 0.6356033452807647\n",
      "Recall: 0.4307692307692308\n"
     ]
    }
   ],
   "source": [
    "test_probabilities = cb_clf.predict_proba(X_test_proc)[:, 1]\n",
    "\n",
    "test_classes = cb_clf.predict(X_test_proc)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, test_classes)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, test_classes)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, test_probabilities)}\") # Use probabilities\n",
    "print(f\"PR AUC (Average Precision): {average_precision_score(y_test, test_probabilities)}\") # Use probabilities\n",
    "print(f\"Precision: {precision_score(y_test, test_classes)}\")\n",
    "print(f\"Recall: {recall_score(y_test, test_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost with Randomized Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting randomized search tuning...\n",
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n",
      "Randomized search complete. Time taken: 418.14 seconds\n",
      "\n",
      "Best parameters:\n",
      "  subsample: 0.5\n",
      "  rsm: 1.0\n",
      "  n_estimators: 2000\n",
      "  learning_rate: 0.01\n",
      "  l2_leaf_reg: 13\n",
      "  depth: 2\n",
      "\n",
      "Best cross-validation accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting randomized search tuning...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Define a larger parameter space\n",
    "param_dist = {\n",
    "    'depth': [2, 3, 4], \n",
    "    'learning_rate': [0.005, 0.01, 0.015], \n",
    "    'n_estimators': [2000, 2250, 2500],\n",
    "    'subsample': [0.4, 0.5, 0.6],\n",
    "    'rsm': [0.8, 0.9, 1.0],\n",
    "    'l2_leaf_reg': [9, 11, 13]\n",
    "}\n",
    "\n",
    "# Use Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=cb_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=150,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_proc, y_train, verbose=False)\n",
    "\n",
    "random_search_time = time.time() - start_time\n",
    "print(f\"Randomized search complete. Time taken: {random_search_time:.2f} seconds\")\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"\\nBest parameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest cross-validation accuracy: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8194444444444444\n",
      "F1 Score: 0.5222929936305732\n",
      "ROC AUC Score: 0.6830163644405131\n",
      "PR AUC (Average Precision): 0.41539898132427844\n",
      "Precision: 0.6612903225806451\n",
      "Recall: 0.43157894736842106\n"
     ]
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "test_predictions_gs = best_model.predict(X_test_proc)\n",
    "round_test_predictions_gs = [round(p) for p in test_predictions_gs]\n",
    "print(f\"Accuracy: {accuracy_score(y_test, round_test_predictions_gs)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, round_test_predictions_gs)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, test_predictions_gs)}\") # Use probabilities\n",
    "print(f\"PR AUC (Average Precision): {average_precision_score(y_test, test_predictions_gs)}\") # Use probabilities\n",
    "print(f\"Precision: {precision_score(y_test, round_test_predictions_gs)}\")\n",
    "print(f\"Recall: {recall_score(y_test, round_test_predictions_gs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
